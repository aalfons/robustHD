% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/weights.R
\name{weights.penModel}
\alias{weights.penModel}
\alias{weights.sparseLTS}
\title{Extract robustness weights}
\usage{
\method{weights}{penModel}(object, type = "robustness", s = NA,
  drop = !is.null(s), ...)

\method{weights}{sparseLTS}(object, type = "robustness", s = NA,
  fit = c("reweighted", "raw", "both"), drop = !is.null(s), ...)
}
\arguments{
\item{object}{the model fit from which to extract robustness weights.}

\item{type}{the type of weights to be returned.  Currently only robustness
weights are implemented (\code{"robustness"}).}

\item{s}{an integer vector giving the indices of the models for which to
extract robustness weights.  For sparse least trimmed squares models, this
can be a list with two components (if \code{fit} is \code{"both"}), with the
first component giving the indices of the reweighted fits and the second the
indices of the raw fits.  The default is to use the optimal model for each
of the requested estimators.  Note that the optimal models may not
correspond to the same value of the penalty parameter for the reweighted and
the raw estimator.}

\item{drop}{a logical indicating whether to reduce the dimension to a
vector in case of only one model.}

\item{\dots}{currently ignored.}

\item{fit}{a character string specifying for which estimator to extract
outlier weights.  Possible values are \code{"reweighted"} (the default) for
weights indicating outliers from the reweighted fit, \code{"raw"} for
weights indicating outliers from the raw fit, or \code{"both"} for the
outlier weights from both estimators.}
}
\value{
A numeric vector or matrix containing the requested outlier weights.
}
\description{
Extract robustness weights from robust penalized regression models.  For
sparse least trimmed squares regression models, those are binary weights
that indicate outliers.
}
\note{
The weights are \eqn{1} for observations with reasonably small
residuals and \eqn{0} for observations with large residuals.
}
\examples{
## generate data
# example is not high-dimensional to keep computation time low
library("mvtnorm")
set.seed(1234)  # for reproducibility
n <- 100  # number of observations
p <- 25   # number of variables
beta <- rep.int(c(1, 0), c(5, p-5))  # coefficients
sigma <- 0.5      # controls signal-to-noise ratio
epsilon <- 0.1    # contamination level
Sigma <- 0.5^t(sapply(1:p, function(i, j) abs(i-j), 1:p))
x <- rmvnorm(n, sigma=Sigma)    # predictor matrix
e <- rnorm(n)                   # error terms
i <- 1:ceiling(epsilon*n)       # observations to be contaminated
e[i] <- e[i] + 5                # vertical outliers
y <- c(x \%*\% beta + sigma * e)  # response
x[i,] <- x[i,] + 5              # bad leverage points

## sparse LTS over a grid of values for lambda
# fit model
frac <- seq(0.2, 0.05, by = -0.05)
fitGrid <- sparseLTS(x, y, lambda = frac, mode = "fraction")
# extract outlier weights
weights(fitGrid, type = "robustness")
head(weights(fitGrid, type = "robustness", fit = "both"))
head(weights(fitGrid, type = "robustness", s = NULL))
head(weights(fitGrid, type = "robustness", fit = "both", s = NULL))
}
\seealso{
\code{\link{sparseLTS}}
}
\author{
Andreas Alfons
}
\keyword{regression}
