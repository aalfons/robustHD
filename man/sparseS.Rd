% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/sparseS.R
\encoding{utf8}
\name{sparseS}
\alias{sparseS}
\alias{print.sparseS}
\alias{sparseS.formula}
\alias{sparseS.default}
\title{Sparse S-estimator of regression}
\usage{
sparseS(x, ...)

\method{sparseS}{formula}(formula, data, ...)

\method{sparseS}{default}(x, y, lambdaMin = 0, sMax = NA,
  standardize = TRUE, nsamp = c(500, 10), nistep = 10,
  tuning.chi = 1.547645, bb = NULL, nfpi = c(10, 500),
  tol = .Machine$double.eps^0.5, eps = .Machine$double.eps, use.Gram,
  crit = "BIC", ncores = 1, seed = NULL, model = TRUE, ...)
}
\arguments{
\item{x}{a numeric matrix containing the predictor variables.}

\item{\dots}{additional arguments to be passed down.}

\item{formula}{a formula describing the model.}

\item{data}{an optional data frame, list or environment (or object coercible
to a data frame by \code{\link{as.data.frame}}) containing the variables in
the model.  If not found in data, the variables are taken from
\code{environment(formula)}, typically the environment from which
\code{sparseS} is called.}

\item{y}{a numeric vector containing the response variable.}

\item{standardize}{a logical indicating whether the response and predictor
variables should be robustly standardized (the default is \code{TRUE}).  See
\code{\link[=standardize]{robStandardize}}.}

\item{nsamp}{a numeric vector giving the number of resamples to be used in
the two phases of the algorithm.  The first element gives the number of
initial resamples to be used.  The second element gives the number of
resamples to keep after the first phase of \code{nistep} I-steps.  For
those remaining resamples, additional I-steps are performed until
convergence.  The default is to first perform \code{nistep} I-steps on 500
initial resamples, and then to keep the 10 resamples with the lowest value
of the objective function for additional I-steps until convergence.}

\item{nistep}{a positive integer giving the number of I-steps to perform on
all resamples in the first phase of the algorithm (the default is to
perform 10 I-steps).}

\item{tuning.chi}{numeric; tuning constant of Tukey's bisquare function
that determines the robustness of the sparse S-estimator.  The default value
yields an asymptotic breakdown point of 50\%.  Use value 2.937015 for an
asymptotic breakdown point of 25\%.}

\item{bb}{numeric; expected value of the M-scale.  The default value is
computed under the normal model with tuning constant equal to
\code{tuning.chi}.}

\item{nfpi}{a numeric vector of length two giving the maximum number of
fixed point iterations to be used for computing the M-scale.  The first
value is used in the first phase of the algorithm when \code{nistep} I-steps
are performed on all resamples, the second value is used in the second phase
when I-steps are performed until convergence on the best resamples.}

\item{tol}{a small positive numeric value giving the tolerance for
convergence.}

\item{eps}{a small positive numeric value used to determine whether the
variability within a variable is too small (an effective zero).}

\item{use.Gram}{a logical indicating whether the Gram matrix of the
explanatory variables should be precomputed in the weighted lasso fits.  If
the number of variables is large, computation may be faster when this is set
to \code{FALSE}.  The default is to use \code{TRUE} if the number of
variables is smaller than the number of observations and smaller than 100,
and \code{FALSE} otherwise.}

\item{crit}{a character string specifying the optimality criterion to be
used for selecting the final model.  Currently only \code{"BIC"} for
the Bayes information criterion is implemented.}

\item{ncores}{a positive integer giving the number of processor cores to be
used for parallel computing (the default is 1 for no parallelization).  If
this is set to \code{NA}, all available processor cores are used.  Parallel
computing is implemented on the C++ level via OpenMP
(\url{http://openmp.org/}).}

\item{seed}{optional initial seed for the random number generator (see
\code{\link{.Random.seed}}).}

\item{model}{a logical indicating whether the data \code{x} and \code{y}
should be added to the return object.  A column of ones is added to \code{x}
to account for the intercept.}

\item{lambda}{a numeric vector of non-negative values to be used as penalty
parameter.  Defaults to \code{NULL}, in which case the optimal value of the
penalty parameter according to BIC is determined in each weighted lasso fit
in the iterative algorithm.}
}
\value{
An object of class \code{"sparseS"} (inheriting from class
\code{"penModel"}) with the following components:
\item{lambda}{a numeric vector giving the values of the penalty
parameter.}
\item{rweights}{an integer vector or matrix containing the respective
robustness weights.}
\item{objective}{a numeric vector giving the respective values of the
sparse S objective function, i.e., the \eqn{L_{1}}{L1} penalized sums of
the M-scales of the residuals.}
\item{coefficients}{a numeric vector or matrix containing the
respective coefficient estimates.}
\item{fitted.values}{a numeric vector or matrix containing the
respective fitted values of the response.}
\item{residuals}{a numeric vector or matrix containing the
respective residuals.}
\item{scale}{a numeric vector giving the minimized M-scale estimates
of the corresponding residuals.}
\item{df}{an integer vector giving the respective degrees of freedom
of the obtained model fits, i.e., the number of nonzero coefficient
estimates.}
\item{standardize}{a logical indicating whether the predictor
variables were robustly standardized.}
\item{crit}{an object of class \code{"bicSelect"} containing the BIC
values and indicating the final model (only returned if argument \code{crit}
is \code{"BIC"} and argument \code{lambda} contains more than one value for
the penalty parameter).}
\item{muX}{a numeric vector containing the center estimates of the
predictors if \code{standardize=TRUE} and a numeric vectors of zeros
otherwise.}
\item{sigmaX}{a numeric vector containing the scale estimates of the
predictors if \code{standardize=TRUE} and a numeric vectors of ones
otherwise.}
\item{muY}{numeric; the center estimate of the response if
\code{standardize=TRUE} and a numeric vectors of zeros otherwise.}
\item{sigmaY}{numeric; the scale estimate of the response if
\code{standardize=TRUE} and a numeric vectors of ones otherwise.}
\item{x}{the predictor matrix (if \code{model} is \code{TRUE}).}
\item{y}{the response variable (if \code{model} is \code{TRUE}).}
\item{call}{the matched function call.}
}
\description{
Compute the S-estimator of regression with an \eqn{L_{1}}{L1} penalty on
the regression coefficients, which allows for sparse model estimates.
}
\seealso{
\code{\link[=coef.penModel]{coef}},
\code{\link[=fitted.penModel]{fitted}},
\code{\link[=plot.penModel]{plot}},
\code{\link[=predict.penModel]{predict}},
\code{\link[=residuals.penModel]{residuals}},
\code{\link[=weights.penModel]{weights}}
}
\author{
Andreas Alfons and Viktoria \enc{Ã–llerer}{Oellerer}
}
\keyword{regression}
\keyword{robust}
