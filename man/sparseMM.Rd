% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/sparseMM.R
\encoding{utf8}
\name{sparseMM}
\alias{sparseMM}
\alias{print.sparseMM}
\alias{sparseMM.formula}
\alias{sparseMM.default}
\title{Sparse MM-estimator of regression}
\usage{
sparseMM(x, ...)

\method{sparseMM}{formula}(formula, data, ...)

\method{sparseMM}{default}(x, y, lambdaMin = 0, sMax = NA,
  standardize = TRUE, tuning.psi = 4.685061, max.it = 500,
  nsamp = c(500, 10), nistep = 10, tuning.chi = 1.547645, bb = NULL,
  nfpi = c(10, 500), tol = .Machine$double.eps^0.5,
  eps = .Machine$double.eps, use.Gram, scaleType = c("S", "M", "tau"),
  crit = "BIC", ncores = 1, seed = NULL, model = TRUE, ...)
}
\arguments{
\item{x}{a numeric matrix containing the predictor variables.}

\item{\dots}{additional arguments to be passed down.}

\item{formula}{a formula describing the model.}

\item{data}{an optional data frame, list or environment (or object coercible
to a data frame by \code{\link{as.data.frame}}) containing the variables in
the model.  If not found in data, the variables are taken from
\code{environment(formula)}, typically the environment from which
\code{sparseMM} is called.}

\item{y}{a numeric vector containing the response variable.}

\item{standardize}{a logical indicating whether the response and predictor
variables should be robustly standardized (the default is \code{TRUE}). See
\code{\link[=standardize]{robStandardize}}.}

\item{tuning.psi}{numeric; tuning constant for Tukey's bisquare function
that determines the efficiency. The default value yields 95\% efficiency for
the unpenalized MM-estimator at the regression model with normal errors.
Use value 3.443689 for 85\% efficiency.}

\item{max.it}{integer; the maximum number of iteratively reweighted lasso
iterations.}

\item{nsamp, nistep, tuning.chi, bb, nfpi}{see \code{\link{sparseS}}.}

\item{tol}{a small positive numeric value giving the tolerance for
convergence.}

\item{eps}{a small positive numeric value used to determine whether the
variability within a variable is too small (an effective zero).}

\item{use.Gram}{a logical indicating whether the Gram matrix of the
explanatory variables should be precomputed in the weighted lasso fits. If
the number of variables is large, computation may be faster when this is set
to \code{FALSE}.  The default is to use \code{TRUE} if the number of
variables is smaller than the number of observations and smaller than 100,
and \code{FALSE} otherwise.}

\item{scaleType}{a character string specifying the type of residual scale
estimate.  Possible values are \code{"S"} (the default; the scale estimate
from the initial S-estimator), \code{"M"} (re-estimated M-scale of the final
residuals) and \code{"tau"} (\eqn{\tau}{tau}-estimate of scale of the final
residuals, see \code{\link[robustbase]{scaleTau2}}).}

\item{crit}{a character string specifying the optimality criterion to be
used for selecting the final model.  Currently only \code{"BIC"} for
the Bayes information criterion is implemented.}

\item{ncores}{a positive integer giving the number of processor cores to be
used for parallel computing (the default is 1 for no parallelization).  If
this is set to \code{NA}, all available processor cores are used.  Parallel
computing is implemented on the C++ level via OpenMP
(\url{http://openmp.org/}).}

\item{seed}{optional initial seed for the random number generator (see
\code{\link{.Random.seed}}).}

\item{model}{a logical indicating whether the data \code{x} and \code{y}
should be added to the return object.  A column of ones is added to \code{x}
to account for the intercept.}

\item{lambda}{a numeric vector of non-negative values to be used as penalty
parameter.  Defaults to \code{NULL}, in which case the optimal value of the
penalty parameter according to BIC is determined in each weighted lasso fit
in the iterative algorithm.}

\item{lambdaS}{the values of the penalty parameter for in initial sparse
S-estimator can be specified separately. This should be a numeric vector of
the same length as \code{lambda}.}
}
\value{
An object of class \code{"sparseMM"} (inheriting from class
\code{"penModel"}) with the following components:
\item{lambda}{a numeric vector giving the values of the penalty
parameter.}
\item{rweights}{an integer vector or matrix containing the respective
robustness weights.}
\item{objective}{a numeric vector giving the respective values of the
sparse MM objective function, i.e., the \eqn{L_{1}}{L1} penalized sums of
the M-loss of the scaled residuals.}
\item{coefficients}{a numeric vector or matrix containing the
respective coefficient estimates.}
\item{fitted.values}{a numeric vector or matrix containing the
respective fitted values of the response.}
\item{residuals}{a numeric vector or matrix containing the
respective residuals.}
\item{scale}{a numeric vector giving the robust scale estimates of the
corresponding residuals.}
\item{df}{an integer vector giving the respective degrees of freedom
of the obtained model fits, i.e., the number of nonzero coefficient
estimates.}
\item{standardize}{a logical indicating whether the predictor
variables were robustly standardized.}
\item{init.S}{a list containing the results of the initial sparse
S-estimator.}
\item{crit}{an object of class \code{"bicSelect"} containing the BIC
values and indicating the final model (only returned if argument \code{crit}
is \code{"BIC"} and argument \code{lambda} contains more than one value for
the penalty parameter).}
\item{muX}{a numeric vector containing the center estimates of the
predictors if \code{standardize=TRUE} and a numeric vectors of zeros
otherwise.}
\item{sigmaX}{a numeric vector containing the scale estimates of the
predictors if \code{standardize=TRUE} and a numeric vectors of ones
otherwise.}
\item{muY}{numeric; the center estimate of the response if
\code{standardize=TRUE} and a numeric vectors of zeros otherwise.}
\item{sigmaY}{numeric; the scale estimate of the response if
\code{standardize=TRUE} and a numeric vectors of ones otherwise.}
\item{x}{the predictor matrix (if \code{model} is \code{TRUE}).}
\item{y}{the response variable (if \code{model} is \code{TRUE}).}
\item{call}{the matched function call.}
}
\description{
Compute the MM-estimator of regression with an \eqn{L_{1}}{L1} penalty on
the regression coefficients, which allows for sparse model estimates.
}
\seealso{
\code{\link[=coef.penModel]{coef}},
\code{\link[=fitted.penModel]{fitted}},
\code{\link[=plot.penModel]{plot}},
\code{\link[=predict.penModel]{predict}},
\code{\link[=residuals.penModel]{residuals}},
\code{\link[=weights.penModel]{weights}},
\code{\link[robustbase]{lmrob}}
}
\author{
Andreas Alfons and Viktoria \enc{Ã–llerer}{Oellerer}
}
\keyword{regression}
\keyword{robust}
